{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b9f34373-7724-4261-a1a1-d50fda1eab1f",
      "metadata": {
        "id": "b9f34373-7724-4261-a1a1-d50fda1eab1f"
      },
      "source": [
        "# Probability\n",
        "## Foundations of Machine Learning\n",
        "## `! git clone https://www.github.com/DS3001/probability`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98ef2709-651c-4e2a-9cd2-196c7ff931c1",
      "metadata": {
        "id": "98ef2709-651c-4e2a-9cd2-196c7ff931c1"
      },
      "source": [
        "## Probability\n",
        "- So we have some skills to get data and put into a workable form (data wrangling, EDA, visualization)\n",
        "- We have some basic but powerful tools to analyze data and create predictive models ($k$NN, $k$MC, linear models, decision trees)\n",
        "- We want to ask questions like, How much uncertainty does there appear to be in our predictions? How well is this model likely to perform on new data? Does this model work well in any absolute sense?\n",
        "- To proceed, we need to add some more ideas about probability and randomness, in order to communicate with each other and understand tools\n",
        "- These two lectures (probability and bootstrapping) are probably the most difficult in the class, but the payoff is absolutely worth it"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "821aac76-aff4-484d-9da4-159c814b813d",
      "metadata": {
        "id": "821aac76-aff4-484d-9da4-159c814b813d"
      },
      "source": [
        "## A Fair Die\n",
        "- Let's consider something very simple: Rolling a \"fair\" 6-sided die where each side is equally likely.\n",
        "- There are six sides with pips $\\cdot$, $2\\cdot$, $3\\cdot$, $4\\cdot$, $5\\cdot$, and $6 \\cdot$\n",
        "- Besides the sides themselves, we can define outcomes like *odd*, $\\left\\lbrace 1\\cdot, 3\\cdot, 5\\cdot \\right\\rbrace$, and *even*, $\\left\\lbrace 2\\cdot, 4\\cdot, 6\\cdot \\right\\rbrace$.\n",
        "- If each side is equally likely, the probability we observe any given side should be 1/6; this allows us to work out the likelihood of observing any particular collection of sides, like even or odd.\n",
        "- What are all these ideas, in an abstract sense??"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7af47cf4-ee4c-4ded-9b7a-d2e0662aac4f",
      "metadata": {
        "id": "7af47cf4-ee4c-4ded-9b7a-d2e0662aac4f"
      },
      "source": [
        "## A Fair Die\n",
        "- There are six sides with pips $\\cdot$, $2\\cdot$, $3\\cdot$, $4\\cdot$, $5\\cdot$, and $6\\cdot$. **This is called the *sample space* and each possibility in it is called an outcome**.\n",
        "- Besides the sides themselves, we can define outcomes like *odd*, $\\left\\lbrace 1\\cdot, 3\\cdot, 5\\cdot \\right\\rbrace$, and *even*, $\\left\\lbrace 2\\cdot, 4\\cdot, 6\\cdot \\right\\rbrace$. **This is called the set of *events*: all of the \"relevant\" sets of outcomes that might occur.**\n",
        "- If each side is equally likely, the probability we observe any given side should be 1/6; this allows us to work out the likelihood of observing any particular collection of sides, like even or odd. **This is called a *probability function*, associating every event with a number between 0 and 1.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16032d51-a757-4f8f-9c2b-d80019fa383c",
      "metadata": {
        "id": "16032d51-a757-4f8f-9c2b-d80019fa383c"
      },
      "source": [
        "## Probabilities\n",
        "- There are many nuances about what rules a \"probability function\" must satisfy that we are going to gloss over\n",
        "- The key rules are these:\n",
        "  - The probability of nothing happening is zero, the probability of something happening is 1\n",
        "  - The probability of every event is between zero and 1\n",
        "  - If you have a set of events $e_1, e_2, ..., e_N$ where no outcome occurs in more than one event (e.g. even and odd), then\n",
        "  $$\n",
        "  p(e_1 \\text{ and } e_2 \\text{ and } ... \\text{ and } e_n) = p(e_1) + p(e_2) + ... + p(e_N)\n",
        "  $$\n",
        "- Everything we talk about today holds for situations where there are a finite or infinite number of outcomes, as long as you set things up \"correctly\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c2eb711-265d-43b7-a1e0-7074c373bc42",
      "metadata": {
        "id": "8c2eb711-265d-43b7-a1e0-7074c373bc42"
      },
      "source": [
        "## Notation\n",
        "- Let's call the sample space $S$ and individual outcomes $x$\n",
        "- Let's call the set of all events $E$ and an individual event $e$\n",
        "- Let's call the probability function $p(e)$\n",
        "- We can write that $p(S)=1$, $0 \\le p(e) \\le 1$ for all events $e$ in $E$, and if every outcome appears at most once in a set of events $e_1, ..., e_n$, $p(e_1 \\text{ and } e_2 \\text{ and } ... \\text{ and }e_n) = \\sum_{i=1}^n p(e_i)$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "516db8cf-35bc-4fb0-8b92-1fe51057acdd",
      "metadata": {
        "id": "516db8cf-35bc-4fb0-8b92-1fe51057acdd"
      },
      "source": [
        "## Betting on Dice\n",
        "- For example, let's bet on the roll of two six-sided die\n",
        "- An outcome is a pair of die faces, like $(3\\cdot,6\\cdot)$. The sample space is:\n",
        "$$\n",
        "\\left[ \\begin{array}{cccccc}\n",
        "(1\\cdot,1\\cdot) & (1\\cdot,2\\cdot) & (1\\cdot,3\\cdot) & (1\\cdot,4\\cdot) & (1\\cdot,5\\cdot) & (1\\cdot,6\\cdot) \\\\\n",
        "(2\\cdot,1\\cdot) & (2\\cdot,2\\cdot) & (2\\cdot,3\\cdot) & (2\\cdot,4\\cdot) & (2\\cdot,5\\cdot) & (2\\cdot,6\\cdot) \\\\\n",
        "(3\\cdot,1\\cdot) & (3\\cdot,2\\cdot) & (3\\cdot,3\\cdot) & (3\\cdot,4\\cdot) & (3\\cdot,5\\cdot) & (3\\cdot,6\\cdot) \\\\\n",
        "(4\\cdot,1\\cdot) & (4\\cdot,2\\cdot) & (4\\cdot,3\\cdot) & (4\\cdot,4\\cdot) & (4\\cdot,5\\cdot) & (4\\cdot,6\\cdot) \\\\\n",
        "(5\\cdot,1\\cdot) & (5\\cdot,2\\cdot) & (5\\cdot,3\\cdot) & (5\\cdot,4\\cdot) & (5\\cdot,5\\cdot) & (5\\cdot,6\\cdot) \\\\\n",
        "(6\\cdot,1\\cdot) & (6\\cdot,2\\cdot) & (6\\cdot,3\\cdot) & (6\\cdot,4\\cdot) & (6\\cdot,5\\cdot) & (6\\cdot,6\\cdot)\n",
        "\\end{array} \\right]\n",
        "$$\n",
        "- The events $E$ are all of the subsets of the above matrix (e.g. \"All rolls where both results are even\", \"all rolls that sum to 7\", \"All rolls where both the dice show the same outcome\")\n",
        "- For fair dice, each pair above is equally likely with probabilty $1/36$\n",
        "- Notice, the outcomes here aren't strictly numeric: They could be colors, animals, job titles, car models, anything. Outcomes aren't fundamentally numeric."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76d1776a-fb99-4cb1-853b-66a30b126d8f",
      "metadata": {
        "id": "76d1776a-fb99-4cb1-853b-66a30b126d8f"
      },
      "source": [
        "## Random Variables\n",
        "- A **random variable** is a rule that assigns numbers to outcomes\n",
        "- A random variable is a function $R$ that assigns a number $R(x)$ to each outcome $x$ in $S$\n",
        "- A random variable is how we quantify the consequences of an uncertain phenomenon"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bf43332-b852-49d4-acb3-5b24d9822e85",
      "metadata": {
        "id": "7bf43332-b852-49d4-acb3-5b24d9822e85"
      },
      "source": [
        "## The Expectation\n",
        "- What value is a random variable going to take?\n",
        "- Since a random variable is a rule that assigns a numeric value to every outcome, we can weight those values by the probabilities they occur, and sum:\n",
        "$$\n",
        "\\mathbb{E}[R] = p(x_1) R(x_1) + p(x_2)R(x_2) + ... + p(x_N)R(x_N) = \\sum_{i =1}^N p(x_i)R(x_i)\n",
        "$$\n",
        "- If the outcomes are numbers and all equally likely, we can set $R(x_i) = x_i$ and $p(x_i) = 1/N$, which gives\n",
        "$$\n",
        "\\mathbb{E}[R] = \\dfrac{1}{N} x_1 + \\dfrac{1}{N} x_2 + ... + \\dfrac{1}{N} x_N = \\dfrac{1}{N} \\sum_{i =1}^N x_i\n",
        "$$\n",
        "- This is called the **expectation of $R$** or the **expected value of $R$**. It is often denoted by $\\mu$ or $\\mu_R$, to emphasize it's a theoretical/population value."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fe0c9a9-b1a5-4b59-aabe-d3410524798a",
      "metadata": {
        "id": "9fe0c9a9-b1a5-4b59-aabe-d3410524798a"
      },
      "source": [
        "## Gambling\n",
        "- What's the expected value of rolling two dice, if you get the sum of the faces in money?\n",
        "- What's the expected value of a gamble where you get $\\$10$ if the sum is strictly greater than 7, but $\\$0$ if the sum is weakly less than 7?\n",
        "- What's the expected value of a gamble where you get $\\$$100 if the sum is odd? Even?\n",
        "- What would you will be willing to pay for the above gambles?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ffd68c9-4402-443e-85d2-9bcb2b046209",
      "metadata": {
        "id": "6ffd68c9-4402-443e-85d2-9bcb2b046209"
      },
      "source": [
        "## The Variance\n",
        "- The **variance of $R$** is\n",
        "$$\\mathbb{V}[R] = p(x_1)(R(x_1)-\\mathbb{E}[R])^2 + p(x_2)(R(x_2)-\\mathbb{E}[V])^2 +\n",
        "... + p(x_N)(R(x_N)-\\mathbb{E}[R])^2 = \\sum_{i=1}^N p(x_i)(R(x_i)-\\mathbb{E}[R])^2\n",
        "$$\n",
        "- You can also write this as\n",
        "$$\n",
        "\\mathbb{V}[R] = \\mathbb{E}\\left[ (R-\\mathbb{E}[R])^2\\right]= \\mathbb{E}\\left[ (R-\\mu_R)^2\\right]\n",
        "$$\n",
        "- The variance is often denoted $\\sigma^2$ or $\\sigma_R^2$, to emphasize it's a theoretical/population value."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a18ad45e-d8fa-439f-a108-a7d83a93d4f0",
      "metadata": {
        "id": "a18ad45e-d8fa-439f-a108-a7d83a93d4f0"
      },
      "source": [
        "## Random Number Generation in Python\n",
        "- Suppose you have a set $S$, like $S = \\{1,2,3,4,5,6\\}$, or `S = np.arange(6)+1`. For example, suppose you want to sample observations from your data frame: that corresponds to `np.arange( df.shape[0])`.\n",
        "    - To **sample with replacement**, you can use Numpy's `random.choice(S,size=n)` function to take $n$ draws from $S$, with the potential for repetition\n",
        "    - To **sample without replacement**, you can use Numpy's `np.random.shuffle(S)` function to randomize the order of the elements in $S$, and then $S[:N]$ to slice the first $N$ elements from the shuffled $S$\n",
        "- To draw `N` numbers from between 0 and 1 with uniform probability, you can use `np.random.uniform(size=N)`\n",
        "- To draw `N` numbers from a normal distribution with mean $m$ and standard deviation $s$, you can use `np.random.normal(m,s,size=N)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ad2bc12-93dd-438d-838f-84ee0b9564ef",
      "metadata": {
        "id": "0ad2bc12-93dd-438d-838f-84ee0b9564ef",
        "outputId": "8c27030c-0341-4dd7-9742-d12f3e07861d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5 1 2]\n",
            "[1 1 3 4 3 1 4 4 3 3]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "S = np.array([1,2,3,4,5,6]) # Object to sample\n",
        "x = np.random.choice(S, size=3)\n",
        "print(x)\n",
        "x = np.random.choice(S, size=10)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e912cd8-54d4-4a54-9eb2-64d64ac4f3da",
      "metadata": {
        "id": "8e912cd8-54d4-4a54-9eb2-64d64ac4f3da",
        "outputId": "13b023af-4b1e-4e98-c5b0-62ecbf9b0fe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[6 1 3 4 5 2]\n",
            "[6 1 3]\n"
          ]
        }
      ],
      "source": [
        "S = np.array([1,2,3,4,5,6]) # Object to sample\n",
        "N = 3 # Elements to take\n",
        "\n",
        "np.random.shuffle(S) # 1. Shuffle x\n",
        "print(S)\n",
        "y = S[:N] # 2. Take the first N elements\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e40907be-367e-4a2e-be2a-c9dec29ebfea",
      "metadata": {
        "id": "e40907be-367e-4a2e-be2a-c9dec29ebfea",
        "outputId": "40d242a2-aeab-43b5-f1ce-51d2c74590e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2.77220188e-01, 2.09544120e-01, 1.30356424e-02, 1.92719556e-01,\n",
              "       5.99456346e-01, 9.62899767e-01, 4.34549892e-04, 7.49748596e-02,\n",
              "       7.09421198e-02, 4.31349831e-01])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.random.uniform(size=10) # A random sample of uniformly distributed numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bb24ece-0c08-4ea6-b76a-947460ba5c8a",
      "metadata": {
        "id": "6bb24ece-0c08-4ea6-b76a-947460ba5c8a",
        "outputId": "15976838-8c53-4db6-e000-30fc3474e51d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([17.86566832, 13.68901458,  6.96449255, 13.42888148,  9.45935987,\n",
              "       16.79135465,  2.6811557 ,  6.66369038, 16.44308665, 17.78716328])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.random.normal(10,5,size=10) # A random sample of normally distributed numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6dab6ca-bf56-4fc8-b21f-6591e7af88ba",
      "metadata": {
        "id": "f6dab6ca-bf56-4fc8-b21f-6591e7af88ba"
      },
      "source": [
        "## Gambling\n",
        "- What's the variance of rolling two dice and summing?\n",
        "- What's the variance of a gamble where you get $\\$10$ if the sum is strictly greater than 7, but $\\$0$ if the sum is weakly less than 7?\n",
        "- What's the variance of a gamble where you get $\\$100$ if the sum is odd? Even?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48a2fd85-0991-4530-942f-a13954638e15",
      "metadata": {
        "id": "48a2fd85-0991-4530-942f-a13954638e15"
      },
      "source": [
        "## The Law of Large Numbers\n",
        "- The next five slides are about expanding your understanding of the fundamental nature of reality\n",
        "- If you are the kind of person who says they \"do not like math\" or \"are not good at math\", that's OK, this isn't on a test\n",
        "- This is what real, useful mathematics looks like: A sequence of logical inferences which come together in a powerful insight about quantitative reality\n",
        "- Even if you don't understand every line and manipulation, knowing roughly how humans create quantitative ideas and statistical evidence means your understanding of what is possible expands, and that is valuable on its own"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4f19bfc-084b-419a-a27f-02a861d03dd5",
      "metadata": {
        "id": "b4f19bfc-084b-419a-a27f-02a861d03dd5"
      },
      "source": [
        "## Markov's Inequality\n",
        "- Suppose that $R(x_i) \\ge 0$, so all the random variable only takes non-negative values\n",
        "- Pick a value $a$ that is between $x_1$ and $x_N$. What can we say about the relationship between $p$, $\\mathbb{E}[R]$, and $a$?\n",
        "\\begin{eqnarray*}\n",
        "\\mathbb{E}[R] &=& \\sum_{R(x_i) < a} p(x_i) R(x_i) + \\sum_{R(x_i) \\ge a} p(x_i) R(x_i) \\\\\n",
        "& \\ge & \\sum_{R(x_i) < a} p(x_i) 0 + \\sum_{R(x_i) \\ge a} p(x_i) R(x_i) \\\\\n",
        "& \\ge & \\sum_{R(x_i) \\ge a} p(x_i) a \\\\\n",
        "& =& p[R \\ge a] a\n",
        "\\end{eqnarray*}\n",
        "- This implies that if $R(x) \\ge 0$ for all $x$ in $S$, then for any $a$,\n",
        "$$\n",
        "p[R \\ge a] \\le \\dfrac{\\mathbb{E}[R]}{a}\n",
        "$$\n",
        "- This is called **Markov's Inequality**: The probability that a non-negative random variable exceeds a threshold (a) is bounded by its expectation divided by the threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- everything above a, we round down to a. everything below a gets rounded down to 0"
      ],
      "metadata": {
        "id": "bhGfS1oIIzcW"
      },
      "id": "bhGfS1oIIzcW"
    },
    {
      "cell_type": "markdown",
      "id": "fc4c53e3-db53-4d47-b5ec-7f719f50c744",
      "metadata": {
        "id": "fc4c53e3-db53-4d47-b5ec-7f719f50c744"
      },
      "source": [
        "## Chebyshev's Inequality\n",
        "- OK, can we relate $\\mathbb{E}[R]$, $p$, and $\\sigma$ in a useful way?\n",
        "- If we use Markov's inequality with $R(x) = (x-\\mu)^2$, we get another useful inequality:\n",
        "\\begin{eqnarray*}\n",
        "p[ |x-\\mu| \\ge d ] &=& p[ (x-\\mu)^2 \\ge d^2 ] \\\\\n",
        "&\\le& \\dfrac{\\mathbb{E}[ (X-\\mu)^2 ]}{d^2 }\\\\\n",
        "p[ |x-\\mu| \\ge d  ] &\\le & \\dfrac{\\sigma^2}{d^2 }\\\\\n",
        "\\end{eqnarray*}\n",
        "- This provides a bound on how far a random variable $R(x)=x$ can be from its average, based on the variance $\\sigma^2$ and a distance $d$:\n",
        "$$\n",
        "p\\left[ |x-\\mu| \\ge d \\right] \\le \\dfrac{\\sigma^2}{d^2}\n",
        "$$\n",
        "- This is called **Chebyshev's Inequality**: The distance $d$ a random variable $X$ is from its mean $\\mu$ is bounded by its variance $\\sigma^2$ divided by the distance squared $d^2$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbeac622-ff25-4f70-bb6c-2fb1821a4bf0",
      "metadata": {
        "id": "dbeac622-ff25-4f70-bb6c-2fb1821a4bf0"
      },
      "source": [
        "## Independent and Identically Distributed Sequences (iid)\n",
        "- A fundamental concept in probability and statistics is the abstract idea of running an \"experiment\" over and over, and computing statistics for the results\n",
        "- Let $x_1$ be the result of the first experiment, $x_2$ the result of the second, and so on\n",
        "- Assume that the draws $x_1, x_2, ...$\n",
        "  - are **identically distributed**: They are all drawn from the same distribution function and all have the same mean $\\mu$ and variance $\\sigma^2$\n",
        "  - are **independent**: The outcome of draw $x_n$ doesn't affect the outcome of any draw $x_m$, $m \\neq n$\n",
        "- The **sample average** of our experimental sequence is\n",
        "$$\n",
        "\\bar{X}_n = \\dfrac{1}{N} \\sum_{i=1}^n x_i\n",
        "$$\n",
        "and the **sample variance** of our experimental sequence is\n",
        "$$\n",
        "\\bar{s}_n^2 = \\dfrac{1}{N} \\sum_{i=1}^n (x_i - \\bar{X}_n)^2\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "455ec9e8-0dbd-4965-93a4-e1d6eefe8fae",
      "metadata": {
        "id": "455ec9e8-0dbd-4965-93a4-e1d6eefe8fae"
      },
      "source": [
        "## Independent and Identically Distributed Sequences (iid)\n",
        "- The sample average and sample variance are now, themselves, random variables, with their own outcomes, events, probabilities, and so on\n",
        "- What is the expected value of $\\bar{X}_n$?\n",
        "$$\n",
        "\\mathbb{E}[\\bar{X}_n] = \\mathbb{E}\\left[ \\dfrac{1}{n}(x_1 + ... + x_n)\\right] = \\dfrac{\\mathbb{E}[x_1] + ... + \\mathbb{E}[x_n]}{n} =\n",
        "\\dfrac{\\mu + ... + \\mu}{n} = \\dfrac{n\\mu}{n} = \\mu\n",
        "$$\n",
        "- Likewise (but slightly different steps)\n",
        "$$\n",
        "\\mathbb{V}[\\bar{X}_n] = \\dfrac{\\sigma^2}{n}\n",
        "$$\n",
        "- To emphasize that the sample space of $S_n$ depends on the sequence $n$, we'll write the probability function as $p_n$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af25833f-7f0b-4db4-9fcb-30484e937c2c",
      "metadata": {
        "id": "af25833f-7f0b-4db4-9fcb-30484e937c2c"
      },
      "source": [
        "## Law of Large Numbers\n",
        "- Take the random variable as the sample mean $X_n$ of a sequence of iid random variables, with mean $\\bar{X}_n = \\dfrac{1}{n} \\sum_{t=1}^n x_i$ and variance $\\mathbb{V}[\\bar{X}_n] = \\sigma^2/n$\n",
        "- By Chebyshev's inequality,\n",
        "$$\n",
        "p_n\\left[ |\\bar{X}_n - \\mu|  \\ge d \\right] \\le \\dfrac{\\mathbb{V}[\\bar{X}_n]}{d^2} = \\dfrac{\\sigma^2}{n d^2}.\n",
        "$$\n",
        "- **As $n$ gets large on the far right, $\\frac{\\sigma^2}{nd^2}$ goes to zero, for any $d$.**\n",
        "- The importance of this idea cannot be understated: This is one of the most important ideas that humanity has discovered\n",
        "- This is called the **Law of Large Numbers**: Sample averages *converge in probability* to the true average $\\mu$ as long as the variance $\\sigma^2$ is finite."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff10db5b-9f9e-4b00-9e43-18221564559c",
      "metadata": {
        "id": "ff10db5b-9f9e-4b00-9e43-18221564559c"
      },
      "source": [
        "## Example: Estimating Probabilities\n",
        "- R is going to draw a number $h$ between 0 and 1, but it isn't going to tell us what it is. R will, however, flip a coin that comes up heads[1] with probability $h$ or tails[0] with probability $1-h$\n",
        "- Each flip $x_i$ is either equal to 0 for tails or 1 for heads, so the average of the flips is\n",
        "$$\n",
        "\\bar{X}_n = \\dfrac{x_1+x_2 + ... + x_n}{n} = \\{\\text{The sample proportion of heads}\\} = h_n\n",
        "$$\n",
        "- As the number of flips gets large, by the LLN, the sample average $h_n$ will converge in probability to the true value $h$\n",
        "- As a consequence of the LLN, *sample proportions converge to population probabilities as the sample gets large*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a27e7e0-4192-4ca3-bda2-a8ebc950dd22",
      "metadata": {
        "id": "6a27e7e0-4192-4ca3-bda2-a8ebc950dd22",
        "outputId": "d4cfa909-0bfb-436e-9f8d-ea3114df6412"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.3\n",
            "0.36252279833801393\n"
          ]
        }
      ],
      "source": [
        "# Data generation:\n",
        "h = np.random.uniform() # Unfair coin we don't observe\n",
        "n = 100 # Sample Size\n",
        "flips =  np.random.uniform(size=n) < h  # Flips we observe\n",
        "\n",
        "# Our analysis of the data, 'flips':\n",
        "h_n = flips.mean() # Our estimate of h\n",
        "print(h_n)\n",
        "\n",
        "# What's the true value?\n",
        "print(h) # True value\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43087da1-febb-4341-bf85-87c02247265d",
      "metadata": {
        "id": "43087da1-febb-4341-bf85-87c02247265d"
      },
      "source": [
        "## Example: Estimating Averages\n",
        "- Any given outcome of a gamble is not informative of the value of the gamble in expectation\n",
        "- But if we average many iid plays of the gamble and average the payoffs, the LLN tells us that the sample average will converge to the true value of the gamble\n",
        "- The expected value calculations we were doing earlier by hand can be done by simulation on a computer\n",
        "- This is all mathematical finance/engineering is: More complex versions of this kind of calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc4c357f-b89f-4546-97ad-2c62238bcc91",
      "metadata": {
        "id": "fc4c357f-b89f-4546-97ad-2c62238bcc91",
        "outputId": "b5a0c36d-d163-4640-d162-a1600eb6801b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.23"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set up the gamble:\n",
        "winning_values = np.array([7,11]) # Which values between 2 and 12 count as a 'win'?\n",
        "winning_amount = 1 # Amount received if you win\n",
        "losing_amount = 0 # Amount paid if you lose\n",
        "die = np.arange(6)+1\n",
        "n = 1000 # Number of simulations of the gamble\n",
        "\n",
        "# Simulate the gamble:\n",
        "rolls = np.random.choice(die, size=[n,2])  # Roll 2 dice n times\n",
        "sums = rolls.sum(axis=1)\n",
        "\n",
        "# Determine winning and losing rolls:\n",
        "winning_rolls = np.in1d(sums,winning_values)\n",
        "losing_rolls = 1-winning_rolls\n",
        "\n",
        "# Compute payoffs:\n",
        "payoff = winning_rolls*winning_amount + losing_rolls*losing_amount\n",
        "\n",
        "# Compute expected payoff:\n",
        "payoff.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce864e93-31ed-47c4-af63-706be9fca36d",
      "metadata": {
        "id": "ce864e93-31ed-47c4-af63-706be9fca36d"
      },
      "source": [
        "## Example: Regression\n",
        "- How do we know regression means anything?\n",
        "- The optimal coefficients in a simple linear regression $\\hat{y}_i = a + b x_i$ can be written\n",
        "\\begin{eqnarray*}\n",
        "a^*_N &=& \\dfrac{1}{N} \\sum_{i=1}^N y_i \\\\\n",
        "b^*_N &=& \\dfrac{ \\frac{1}{N} \\sum_{i=1}^N (y_i - \\bar{y}_n)(x_i-\\bar{x}_n)}{\\frac{1}{N} \\sum_{i=1}^N (x_i- \\bar{x}_n)^2}\n",
        "\\end{eqnarray*}\n",
        "- These are all just sample averages of various kinds. There are rules about how the LLN can be combined with these kinds of functions to know that $a^*_N$ and $b^*_N$ converge since $\\bar{y}_N$ and $\\bar{x}_N$ converge (Slutsky's Theorem, Portmanteau Theorem, Continuous Mapping Theorem).\n",
        "- As the sample size gets large, there are theoretical limit values they converge to: We should expect order to arise out of the randomness, even if we have no idea what they are."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e93f0680-862d-497a-aa4d-c09e94397e02",
      "metadata": {
        "id": "e93f0680-862d-497a-aa4d-c09e94397e02",
        "outputId": "05c20657-cec9-4b16-963f-38001ab8adab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.3389562512450843\n",
            "[2.99058257 5.0926713 ]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "n = 250 # Number of observations\n",
        "\n",
        "## Data creation:\n",
        "b0 = 1 # True intercept coefficient\n",
        "b1 = 3 # True slope coefficient\n",
        "b2 = 5 # True slope coefficient\n",
        "x1 = np.random.normal(5,2,n) # Covariate 1\n",
        "x2 = np.random.normal(-3,1,n) # Covariate 2\n",
        "noise = np.random.normal(0,1,n) # Error term\n",
        "y = b0 + b1*x1 + b2*x2 + noise # Compute Outcome/Target Variable\n",
        "df = pd.DataFrame({'y':y,'x1':x1,'x2':x2}) # Create data frame\n",
        "\n",
        "## Data analysis:\n",
        "from sklearn.linear_model import LinearRegression # Import linear regression model\n",
        "X = df.loc[:,['x1','x2']] # Construct data matrix\n",
        "y = df['y'] # Response variable\n",
        "reg = LinearRegression().fit(X, y) # Fit the linear model\n",
        "print(reg.intercept_) # Intercept value\n",
        "print(reg.coef_) # Regression coefficients\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df809568-f0b5-41a6-8826-b37b6b95c679",
      "metadata": {
        "id": "df809568-f0b5-41a6-8826-b37b6b95c679"
      },
      "source": [
        "## Next Class\n",
        "- We have just admitted that our estimates (the $h_n$, the regression coefficients, etc.) are noisy: They'll be close to the truth if $N$ is large, by the Law of Large Numbers... but we know they're still not *exactly* correct\n",
        "- Can we quantify this uncertainty about our estimates? How?\n",
        "- This is going to motivate a framework called *bootstrapping*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}